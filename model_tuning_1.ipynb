{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cc7af7-5ca2-4964-9014-2001d1f6eca9",
   "metadata": {},
   "source": [
    "# Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6f1fa-ae91-44aa-9584-494fc333388c",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f717e36-0512-47ef-8ec6-c3d7e477d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed5a17-2f6e-48ca-8c19-f5648004befb",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe6d8219-cc64-44c4-b8e5-cf9a7252471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for EEG data with seizure/non-seizure labels.\n",
    "    Can load data directly from HDF5 files.\n",
    "\n",
    "    Attributes:\n",
    "        data (torch.Tensor): Combined EEG data\n",
    "        labels (torch.Tensor): Binary labels (1 for ictal, 0 for interictal)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, data_dir, ictal_filename=\"ictal.h5\", interictal_filename=\"interictal.h5\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with ictal and interictal data,\n",
    "        either directly provided or loaded from files.\n",
    "\n",
    "        Parameters:\n",
    "            data_dir (str): Directory containing HDF5 data files\n",
    "            ictal_filename (str, optional): Filename for ictal data\n",
    "            interictal_filename (str, optional): Filename for interictal data\n",
    "        \"\"\"\n",
    "\n",
    "        ictal_path = os.path.join(data_dir, ictal_filename)\n",
    "        interictal_path = os.path.join(data_dir, interictal_filename)\n",
    "\n",
    "        ictal_file = h5py.File(ictal_path, \"r\")\n",
    "        interictal_file = h5py.File(interictal_path, \"r\")\n",
    "\n",
    "        ictal_data = torch.tensor(np.array(ictal_file[\"data\"]), dtype=torch.float32)\n",
    "        interictal_data = torch.tensor(\n",
    "            np.array(interictal_file[\"data\"]), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Ensure the data is converted to tensors\n",
    "        self.data = torch.cat([ictal_data, interictal_data])\n",
    "        # Labels for ictal and interictal data\n",
    "        self.labels = torch.cat(\n",
    "            [\n",
    "                torch.ones(len(ictal_data)),  # Ictal = 1\n",
    "                torch.zeros(len(interictal_data)),  # Interictal = 0\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_raw = self.data[idx]  # EEG data of shape (22, 2048)\n",
    "        label = self.labels[idx].bool()  # Label: 0 (interictal) or 1 (ictal)\n",
    "        return eeg_raw, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c77bd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./CHB-MIT/processed\"\n",
    "dataset = EEGDataset(data_path)\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ecb71-7087-4c20-bd5d-e238c484ae76",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "From this sample model the data is not time domain but the frequency so it need to do the sfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c370d8ed-1d90-4d9f-aeae-cfb63d865717",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate, SConv2dLSTM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9b2154-7bb5-4965-895f-9228bb20475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_stft(eeg_data, n_fft=256, hop_length=32, win_length=128):\n",
    "    \"\"\"\n",
    "    Apply STFT to batched EEG data using vectorization\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    eeg_data: torch.Tensor\n",
    "        EEG data with shape (batch, channels, time_steps)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    stft_output: torch.Tensor\n",
    "        STFT output with shape (batch, channels, frequency_bins, time_frames)\n",
    "    \"\"\"\n",
    "    batch_size, n_channels, time_steps = eeg_data.shape\n",
    "    window = torch.hann_window(win_length)\n",
    "\n",
    "    # Reshape to (batch*channels, time_steps)\n",
    "    reshaped_data = eeg_data.reshape(-1, time_steps)\n",
    "\n",
    "    # Apply STFT to all channels at once\n",
    "    stft = torch.stft(\n",
    "        reshaped_data,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window=window,\n",
    "        return_complex=True,\n",
    "    )\n",
    "\n",
    "    # Reshape back to (batch, channels, freq_bins, time_frames)\n",
    "    freq_bins, time_frames = stft.shape[1], stft.shape[2]\n",
    "    stft_output = stft.reshape(batch_size, n_channels, freq_bins, time_frames)\n",
    "\n",
    "    return stft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae383bfa-c4f5-465f-8493-30d21d47eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STFTSpikeClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels=22,\n",
    "        threshold=0.05,\n",
    "        slope=13.42287274232855,\n",
    "        beta=0.9181805491303656,\n",
    "        p1=0.5083664100388336,\n",
    "        p2=0.26260898840708335,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        spike_grad = surrogate.straight_through_estimator()\n",
    "        spike_grad2 = surrogate.fast_sigmoid(slope=slope)\n",
    "\n",
    "        # initialize layers - note input_channels=22 for your STFT data\n",
    "        self.lstm1 = SConv2dLSTM(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            max_pool=(2, 1),\n",
    "            threshold=threshold,\n",
    "            spike_grad=spike_grad,\n",
    "        )\n",
    "        self.lstm2 = SConv2dLSTM(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            max_pool=(2, 1),\n",
    "            threshold=threshold,\n",
    "            spike_grad=spike_grad,\n",
    "        )\n",
    "        self.lstm3 = snn.SConv2dLSTM(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            max_pool=(2, 1),\n",
    "            threshold=threshold,\n",
    "            spike_grad=spike_grad,\n",
    "        )\n",
    "\n",
    "        # Calculate the flattened size based on your frequency dimension (129)\n",
    "        # After 3 max-pooling layers (each dividing by 2), size becomes: 129 → 64 → 32 → 16\n",
    "        # For time dimension: 1 (we process one time step at a time)\n",
    "        self.fc1 = nn.Linear(\n",
    "            64 * 16 * 1, 512\n",
    "        )  # Adjust this based on actual output size\n",
    "\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad2, threshold=threshold)\n",
    "        self.dropout1 = nn.Dropout(p1)\n",
    "        self.fc2 = nn.Linear(512, 2)  # Assuming binary classification\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad2, threshold=threshold)\n",
    "        self.dropout2 = nn.Dropout(p2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels=22, freq=129, time=57)\n",
    "        time_steps = x.size(3)\n",
    "\n",
    "        # Initialize LIF state variables\n",
    "        mem4 = self.lif1.init_leaky()\n",
    "        mem5 = self.lif2.init_leaky()\n",
    "        syn1, mem1 = self.lstm1.init_sconv2dlstm()\n",
    "        syn2, mem2 = self.lstm2.init_sconv2dlstm()\n",
    "        syn3, mem3 = self.lstm3.init_sconv2dlstm()\n",
    "\n",
    "        # Output recording\n",
    "        spk5_rec = []\n",
    "        mem5_rec = []\n",
    "\n",
    "        # Process each time step\n",
    "        for step in range(time_steps):\n",
    "            # Extract the current time step and prepare input\n",
    "            # x_t shape: (batch, channels=22, freq=129, time=1)\n",
    "            x_t = x[:, :, :, step].unsqueeze(-1)\n",
    "\n",
    "            # Pass through SConv2dLSTM layers\n",
    "            spk1, syn1, mem1 = self.lstm1(x_t, syn1, mem1)\n",
    "            spk2, syn2, mem2 = self.lstm2(spk1, syn2, mem2)\n",
    "            spk3, syn3, mem3 = self.lstm3(spk2, syn3, mem3)\n",
    "\n",
    "            # Flatten and feed through fully connected layers\n",
    "            cur4 = self.dropout1(self.fc1(spk3.flatten(1)))\n",
    "            spk4, mem4 = self.lif1(cur4, mem4)\n",
    "\n",
    "            cur5 = self.dropout2(self.fc2(spk4))\n",
    "            spk5, mem5 = self.lif2(cur5, mem5)\n",
    "\n",
    "            # Record output spikes and membrane potentials\n",
    "            spk5_rec.append(spk5)\n",
    "            mem5_rec.append(mem5)\n",
    "\n",
    "        # Stack time steps\n",
    "        return torch.stack(spk5_rec), torch.stack(mem5_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93c99fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch.functional as SF\n",
    "from snntorch import spikegen\n",
    "import optuna\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b10d6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define all hyperparameters in a single dictionary\n",
    "    params = {\n",
    "        # Model hyperparameters\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.1),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 5.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.8, 0.99),\n",
    "        \"p1\": trial.suggest_float(\"p1\", 0.3, 0.7),\n",
    "        \"p2\": trial.suggest_float(\"p2\", 0.1, 0.4),\n",
    "        # Optimizer hyperparameters\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        # Scheduler hyperparameters\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.7),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 3, 10),\n",
    "    }\n",
    "\n",
    "    # Create model and optimizer using parameters from the dictionary\n",
    "    model = STFTSpikeClassifier(\n",
    "        input_channels=22,\n",
    "        threshold=params[\"threshold\"],\n",
    "        slope=params[\"slope\"],\n",
    "        beta=params[\"beta\"],\n",
    "        p1=params[\"p1\"],\n",
    "        p2=params[\"p2\"],\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=params[\"lr\"],\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decay=params[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    # Create scheduler with parameters from the dictionary\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=params[\"scheduler_factor\"],\n",
    "        patience=params[\"scheduler_patience\"],\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "\n",
    "    criterion = SF.mse_count_loss()\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 15  # Reduced for hyperparameter search\n",
    "    best_val_loss = 0\n",
    "\n",
    "    print(f\"Trial {trial.number} Starting training...\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for batch_idx, (data, targets) in enumerate(train_loop):\n",
    "            # Preprocess data\n",
    "            scaled_data = vectorized_stft(data)\n",
    "\n",
    "            scaled_data = torch.abs(scaled_data)\n",
    "\n",
    "            if scaled_data.max() > 0:  # Avoid division by zero\n",
    "                scaled_data = scaled_data / scaled_data.max()\n",
    "\n",
    "            data_spike = spikegen.rate(scaled_data, time_var_input=True)\n",
    "\n",
    "            data_spike, targets = data_spike.to(device), targets.to(device)\n",
    "\n",
    "            spk_rec, _ = model(data_spike)\n",
    "\n",
    "            loss_val = criterion(spk_rec, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss_val.item()\n",
    "            spike_sum = torch.sum(spk_rec, dim=0)\n",
    "            _, predicted = torch.max(spike_sum, 1)\n",
    "            total_train += targets.size(0)\n",
    "            correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            train_loop.set_postfix(\n",
    "                loss=train_loss / (batch_idx + 1),\n",
    "                acc=100.0 * correct_train / total_train,\n",
    "            )\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "\n",
    "            for batch_idx, (data, targets) in enumerate(val_loop):\n",
    "                # Preprocess data\n",
    "                scaled_data = vectorized_stft(data)\n",
    "\n",
    "                scaled_data = torch.abs(scaled_data)\n",
    "\n",
    "                if scaled_data.max() > 0:  # Avoid division by zero\n",
    "                    scaled_data = scaled_data / scaled_data.max()\n",
    "\n",
    "                data_spike = spikegen.rate(scaled_data, time_var_input=True)\n",
    "\n",
    "                data_spike, targets = data_spike.to(device), targets.to(device)\n",
    "\n",
    "                spk_rec, _ = model(data_spike)\n",
    "\n",
    "                loss_val = criterion(spk_rec, targets)\n",
    "\n",
    "                val_loss += loss_val.item()\n",
    "                spike_sum = torch.sum(spk_rec, dim=0)\n",
    "                _, predicted = torch.max(spike_sum, 1)\n",
    "                total_val += targets.size(0)\n",
    "                correct_val += (predicted == targets).sum().item()\n",
    "\n",
    "                # Update progress bar\n",
    "                val_loop.set_postfix(\n",
    "                    loss=val_loss / (batch_idx + 1), acc=100.0 * correct_val / total_val\n",
    "                )\n",
    "\n",
    "        # Calculate average metrics\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        if avg_val_loss > best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaa5dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 20:02:40,984] A new study created in RDB with name: Classifier Rate Encoder\n"
     ]
    }
   ],
   "source": [
    "from config import DB_CONFIG\n",
    "\n",
    "study_name = \"Classifier Rate Encoder\"\n",
    "storage_url = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_url,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223435a7",
   "metadata": {},
   "source": [
    "Try optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd25a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 Starting training...\n",
      "Model Parameters: threshold=0.06448990404451335, slope=12.175763805203658, beta=0.9174552042844641, p1=0.460449143369445, p2=0.19889054556671493\n",
      "Optimizer Parameters: lr=3.410877568332701e-06, weight_decay=2.2191678070384094e-05\n",
      "Scheduler Parameters: factor=0.6754745319280612, patience=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.67it/s, acc=49.9, loss=27.9]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.73it/s, acc=49.3, loss=25.4]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=49.9, loss=24.7]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.02it/s, acc=49.3, loss=23.7]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=49.9, loss=24.2]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.32it/s, acc=49.3, loss=23.6]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=49.9, loss=24]  \n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.28it/s, acc=49.3, loss=23.6]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=49.8, loss=21.4]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=49.3, loss=18]  \n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.90it/s, acc=51.1, loss=17.3]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.41it/s, acc=50.7, loss=16.4]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.89it/s, acc=49.6, loss=17.4]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.21it/s, acc=49.1, loss=16.3]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=49.5, loss=17.5]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.79it/s, acc=49.3, loss=16.4]\n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=50.5, loss=17.2]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.37it/s, acc=49.3, loss=16.3]\n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=50.1, loss=17.4]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.19it/s, acc=50.9, loss=16.3]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=50.2, loss=17.2]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.11it/s, acc=51.3, loss=16.3]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.88it/s, acc=49.7, loss=17.4]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.68it/s, acc=49.3, loss=16.3]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.75it/s, acc=49.3, loss=17.4]\n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.20it/s, acc=54.3, loss=16.1]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=51.9, loss=17.1]\n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.89it/s, acc=55.3, loss=15.9]\n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=52, loss=16.9]  \n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.35it/s, acc=57.5, loss=15.6]\n",
      "[I 2025-03-29 20:07:09,190] Trial 0 finished with value: 15.641766726970673 and parameters: {'threshold': 0.06448990404451335, 'slope': 12.175763805203658, 'beta': 0.9174552042844641, 'p1': 0.460449143369445, 'p2': 0.19889054556671493, 'lr': 3.410877568332701e-06, 'weight_decay': 2.2191678070384094e-05, 'scheduler_factor': 0.6754745319280612, 'scheduler_patience': 6}. Best is trial 0 with value: 15.641766726970673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Starting training...\n",
      "Model Parameters: threshold=0.03864053933247167, slope=13.008518626088772, beta=0.8218133922267099, p1=0.35829961853535786, p2=0.3340012776469774\n",
      "Optimizer Parameters: lr=6.647439982852256e-05, weight_decay=1.4701125793602679e-05\n",
      "Scheduler Parameters: factor=0.53324104895912, patience=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.88it/s, acc=71.5, loss=12.8]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.54it/s, acc=75.2, loss=12.8]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=74.7, loss=11.8]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.35it/s, acc=75.4, loss=11.3]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=74.9, loss=11.5]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=77.8, loss=10.9]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=77.2, loss=10.7]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.94it/s, acc=80, loss=9.72]  \n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=77.9, loss=10.3]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.19it/s, acc=80.4, loss=8.97]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.87it/s, acc=77.7, loss=10.2]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.22it/s, acc=81.8, loss=8.55]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=79.2, loss=9.66]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.05it/s, acc=81, loss=9.18]  \n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=79.3, loss=9.56]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.16it/s, acc=79, loss=9.52]  \n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.81it/s, acc=80.3, loss=9.46]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.14it/s, acc=82, loss=8.85]  \n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=81.3, loss=8.8] \n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.00it/s, acc=82.2, loss=8.55]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.69it/s, acc=80.9, loss=9.32]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s, acc=82.4, loss=8.68]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=82.1, loss=8.75]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.96it/s, acc=81.8, loss=9.25]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=81.2, loss=8.86]\n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.28it/s, acc=81.8, loss=9.04]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.90it/s, acc=82.7, loss=8.4] \n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.95it/s, acc=84.8, loss=8.25]\n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=83, loss=8.14]  \n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.18it/s, acc=83.2, loss=7.98]\n",
      "[I 2025-03-29 20:11:36,038] Trial 1 finished with value: 7.9807049036026 and parameters: {'threshold': 0.03864053933247167, 'slope': 13.008518626088772, 'beta': 0.8218133922267099, 'p1': 0.35829961853535786, 'p2': 0.3340012776469774, 'lr': 6.647439982852256e-05, 'weight_decay': 1.4701125793602679e-05, 'scheduler_factor': 0.53324104895912, 'scheduler_patience': 9}. Best is trial 1 with value: 7.9807049036026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Starting training...\n",
      "Model Parameters: threshold=0.07287061067866059, slope=9.694600215402794, beta=0.8925237151942643, p1=0.4794499584056676, p2=0.39160966142797915\n",
      "Optimizer Parameters: lr=8.727020599946896e-05, weight_decay=2.082075892069988e-06\n",
      "Scheduler Parameters: factor=0.5970705832005, patience=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=53.5, loss=18.1]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=69.1, loss=13.1]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=70.3, loss=13.4]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.91it/s, acc=72.7, loss=12.8]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.88it/s, acc=72.5, loss=12.8]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.99it/s, acc=76, loss=11.7]  \n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=75.4, loss=12]  \n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.16it/s, acc=77.2, loss=11.5]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=75.5, loss=11.8]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.91it/s, acc=76.4, loss=11.3]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=76.3, loss=11.6]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.66it/s, acc=77.8, loss=11.3]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=75.7, loss=11.6]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.87it/s, acc=80.2, loss=9.85]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=74.5, loss=11.6]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.15it/s, acc=76.8, loss=10.5]\n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=74.1, loss=11.4]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.88it/s, acc=74.5, loss=11.9]\n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=75.7, loss=11.3]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.98it/s, acc=77.2, loss=10.6]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.80it/s, acc=74.4, loss=11.5]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.91it/s, acc=78.2, loss=10.1]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=74.2, loss=11.4]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.03it/s, acc=73.9, loss=10.7]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=74.7, loss=11.2]\n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.92it/s, acc=77.2, loss=10.3]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.75it/s, acc=76.5, loss=11]  \n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.79it/s, acc=76, loss=10.9]  \n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.95it/s, acc=75.1, loss=11.3]\n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.28it/s, acc=74.1, loss=11.2]\n",
      "[I 2025-03-29 20:16:03,329] Trial 2 finished with value: 11.21290498971939 and parameters: {'threshold': 0.07287061067866059, 'slope': 9.694600215402794, 'beta': 0.8925237151942643, 'p1': 0.4794499584056676, 'p2': 0.39160966142797915, 'lr': 8.727020599946896e-05, 'weight_decay': 2.082075892069988e-06, 'scheduler_factor': 0.5970705832005, 'scheduler_patience': 6}. Best is trial 1 with value: 7.9807049036026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Starting training...\n",
      "Model Parameters: threshold=0.04479117353551371, slope=8.774203968654765, beta=0.8910960846581402, p1=0.4957015394924599, p2=0.33411487612871515\n",
      "Optimizer Parameters: lr=5.8683030602991516e-05, weight_decay=9.274425803742158e-05\n",
      "Scheduler Parameters: factor=0.483866725137161, patience=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=69.5, loss=14.2]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.26it/s, acc=73.3, loss=13.2]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.93it/s, acc=73.2, loss=12.7]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.18it/s, acc=75.4, loss=11.8]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=74.7, loss=12.2]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.84it/s, acc=78, loss=10.5]  \n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=76.5, loss=11.6]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.17it/s, acc=77.8, loss=10.8]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.89it/s, acc=76.1, loss=11.4]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.09it/s, acc=79.4, loss=10.3]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.87it/s, acc=76.6, loss=10.9]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.15it/s, acc=79.6, loss=10.4]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.63it/s, acc=78.1, loss=10.7]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.84it/s, acc=82.4, loss=8.87]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=78.7, loss=10.3]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.96it/s, acc=80, loss=9.67]  \n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=79.3, loss=9.78]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.37it/s, acc=80, loss=9.96]  \n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.91it/s, acc=80.1, loss=9.38]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.21it/s, acc=82.8, loss=9.09]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=82.4, loss=8.87]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.23it/s, acc=84.2, loss=8.38]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=81.4, loss=9.13]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=83.6, loss=8.39]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=83.1, loss=8.49]\n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=84.8, loss=7.56]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=83, loss=8.38]  \n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.04it/s, acc=85, loss=7.41]  \n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=82.5, loss=8.44]\n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.92it/s, acc=84.2, loss=7.68]\n",
      "[I 2025-03-29 20:20:29,354] Trial 3 finished with value: 7.678230956196785 and parameters: {'threshold': 0.04479117353551371, 'slope': 8.774203968654765, 'beta': 0.8910960846581402, 'p1': 0.4957015394924599, 'p2': 0.33411487612871515, 'lr': 5.8683030602991516e-05, 'weight_decay': 9.274425803742158e-05, 'scheduler_factor': 0.483866725137161, 'scheduler_patience': 7}. Best is trial 3 with value: 7.678230956196785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Starting training...\n",
      "Model Parameters: threshold=0.07824082407985902, slope=6.826044776298048, beta=0.8260417395165406, p1=0.39636328939080556, p2=0.36820696571352285\n",
      "Optimizer Parameters: lr=2.3669154777976267e-05, weight_decay=2.738303656044009e-05\n",
      "Scheduler Parameters: factor=0.6197710824867113, patience=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=50.9, loss=17.5]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=50.7, loss=16.3]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.75it/s, acc=49.9, loss=16.9]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.10it/s, acc=50.7, loss=16.3]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.90it/s, acc=53.7, loss=16.2]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=63.9, loss=14.5]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=65.2, loss=13.9]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.73it/s, acc=70.5, loss=12.4]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.80it/s, acc=70.7, loss=12.8]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.15it/s, acc=71.3, loss=12.4]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=71.9, loss=12.5]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.20it/s, acc=71.7, loss=12.2]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.87it/s, acc=73.6, loss=12.1]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.32it/s, acc=74.3, loss=11.8]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.85it/s, acc=73.1, loss=12.1]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.94it/s, acc=75.8, loss=11]  \n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.80it/s, acc=74.2, loss=11.7]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=78.2, loss=10.4]\n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=74.2, loss=11.7]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.79it/s, acc=75.6, loss=11.2]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=75.1, loss=11.7]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.52it/s, acc=77.6, loss=11]  \n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.72it/s, acc=75.1, loss=11.4]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.04it/s, acc=77.2, loss=10.9]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.74it/s, acc=76.2, loss=11.2]\n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.81it/s, acc=77, loss=10.8]  \n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.65it/s, acc=76.7, loss=11.1]\n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.80it/s, acc=78, loss=10.5]  \n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=77, loss=11.2]  \n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.22it/s, acc=78.8, loss=10.4]\n",
      "[I 2025-03-29 20:24:56,862] Trial 4 finished with value: 10.428017675876617 and parameters: {'threshold': 0.07824082407985902, 'slope': 6.826044776298048, 'beta': 0.8260417395165406, 'p1': 0.39636328939080556, 'p2': 0.36820696571352285, 'lr': 2.3669154777976267e-05, 'weight_decay': 2.738303656044009e-05, 'scheduler_factor': 0.6197710824867113, 'scheduler_patience': 10}. Best is trial 3 with value: 7.678230956196785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Starting training...\n",
      "Model Parameters: threshold=0.09126357356035014, slope=12.365422736625243, beta=0.9385282148221409, p1=0.615097377256262, p2=0.3590091027841277\n",
      "Optimizer Parameters: lr=1.4581617681030616e-06, weight_decay=2.5630052903877156e-06\n",
      "Scheduler Parameters: factor=0.5539370028175374, patience=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=50.6, loss=30.2]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.75it/s, acc=50.7, loss=32] \n",
      "[I 2025-03-29 20:25:14,896] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Starting training...\n",
      "Model Parameters: threshold=0.06016048596556808, slope=18.987659739594108, beta=0.8990596590623593, p1=0.6766949211282457, p2=0.12835555755288627\n",
      "Optimizer Parameters: lr=8.371751856084561e-06, weight_decay=3.44703167258735e-06\n",
      "Scheduler Parameters: factor=0.6700420180028217, patience=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=49.8, loss=18.3]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.96it/s, acc=50.7, loss=16.4]\n",
      "[I 2025-03-29 20:25:33,009] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Starting training...\n",
      "Model Parameters: threshold=0.05529288020058422, slope=15.904384394166579, beta=0.9566548316990872, p1=0.5904953087291933, p2=0.23990176190430132\n",
      "Optimizer Parameters: lr=4.962670762161823e-05, weight_decay=1.1912855682621976e-05\n",
      "Scheduler Parameters: factor=0.11658738409354293, patience=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:15<00:00,  6.88it/s, acc=52.9, loss=18.2]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.15it/s, acc=66.7, loss=14.4]\n",
      "[I 2025-03-29 20:25:50,696] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Starting training...\n",
      "Model Parameters: threshold=0.021263450234098438, slope=16.200914614726358, beta=0.8730931261384485, p1=0.6825313616761107, p2=0.10723354973889193\n",
      "Optimizer Parameters: lr=9.586768606327014e-06, weight_decay=1.707889889442616e-06\n",
      "Scheduler Parameters: factor=0.21577091263827713, patience=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=69.5, loss=14.6]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.10it/s, acc=76, loss=11.3]  \n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=75.8, loss=11.7]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.24it/s, acc=81.4, loss=9.96]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=78.1, loss=10.9]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.12it/s, acc=81, loss=9.11]  \n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=77.6, loss=10.5]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.15it/s, acc=81.4, loss=8.63]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.87it/s, acc=78.3, loss=10.4]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.24it/s, acc=82.2, loss=8.76]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=79.3, loss=10.2]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.01it/s, acc=80.4, loss=9.17]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.86it/s, acc=79.4, loss=10.1]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.99it/s, acc=81.4, loss=8.98]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=79.3, loss=10]  \n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.73it/s, acc=81.4, loss=9.3] \n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=79.2, loss=9.99]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.59it/s, acc=82, loss=8.9]   \n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.85it/s, acc=79.9, loss=9.9] \n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.00it/s, acc=82.8, loss=8.34]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=80.1, loss=9.83]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.26it/s, acc=84.2, loss=8.1] \n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=80.9, loss=9.34]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.79it/s, acc=83.8, loss=8.36]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=81.2, loss=9.3] \n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.76it/s, acc=82.4, loss=8.36]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.84it/s, acc=80.4, loss=9.4] \n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.88it/s, acc=80, loss=9.33]  \n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=82.1, loss=9.14]\n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.01it/s, acc=84.8, loss=7.75]\n",
      "[I 2025-03-29 20:30:17,451] Trial 8 finished with value: 7.751927435398102 and parameters: {'threshold': 0.021263450234098438, 'slope': 16.200914614726358, 'beta': 0.8730931261384485, 'p1': 0.6825313616761107, 'p2': 0.10723354973889193, 'lr': 9.586768606327014e-06, 'weight_decay': 1.707889889442616e-06, 'scheduler_factor': 0.21577091263827713, 'scheduler_patience': 5}. Best is trial 3 with value: 7.678230956196785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Starting training...\n",
      "Model Parameters: threshold=0.05166005798355534, slope=18.82464782686074, beta=0.89722841915052, p1=0.6272847695311875, p2=0.1113908078993841\n",
      "Optimizer Parameters: lr=1.766725863319827e-06, weight_decay=3.198584561267529e-06\n",
      "Scheduler Parameters: factor=0.4164529511146198, patience=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.70it/s, acc=49.8, loss=28.8]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.99it/s, acc=49.3, loss=32.4]\n",
      "[I 2025-03-29 20:30:35,609] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Starting training...\n",
      "Model Parameters: threshold=0.012132098425765826, slope=5.180708971964097, beta=0.9880622994503471, p1=0.3042476091940589, p2=0.2986081533533058\n",
      "Optimizer Parameters: lr=2.4409348385523012e-05, weight_decay=9.920452640897283e-05\n",
      "Scheduler Parameters: factor=0.37864766399327154, patience=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=53.2, loss=21.7]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.78it/s, acc=72.9, loss=12.6]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=69.2, loss=13.5]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.03it/s, acc=67.9, loss=13.3]\n",
      "[I 2025-03-29 20:31:11,716] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Starting training...\n",
      "Model Parameters: threshold=0.02270413059124138, slope=8.985894273449363, beta=0.8574555886242518, p1=0.5415481446644633, p2=0.17865513638946257\n",
      "Optimizer Parameters: lr=8.130146004633212e-06, weight_decay=8.432522458031846e-05\n",
      "Scheduler Parameters: factor=0.18934075910498888, patience=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=64.9, loss=16.4]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.84it/s, acc=70.3, loss=13.4]\n",
      "[I 2025-03-29 20:31:29,725] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Starting training...\n",
      "Model Parameters: threshold=0.0367965612687663, slope=15.55032385057343, beta=0.8609754275788617, p1=0.6993496615062764, p2=0.2860289726093579\n",
      "Optimizer Parameters: lr=1.8950187231590773e-05, weight_decay=6.308637548404949e-06\n",
      "Scheduler Parameters: factor=0.2880148158920996, patience=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.70it/s, acc=70, loss=16.7]  \n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.84it/s, acc=75.8, loss=12.3]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=73, loss=13]    \n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.67it/s, acc=75.8, loss=12.5]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.69it/s, acc=73.8, loss=12.5]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s, acc=75.6, loss=11.7]\n",
      "[I 2025-03-29 20:32:23,868] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 Starting training...\n",
      "Model Parameters: threshold=0.03306500797185286, slope=15.856710798061032, beta=0.8599426913445016, p1=0.5221488809826484, p2=0.23979484537328327\n",
      "Optimizer Parameters: lr=3.901127612571515e-06, weight_decay=1.0920407441526752e-06\n",
      "Scheduler Parameters: factor=0.4424599574330864, patience=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=53.3, loss=21.6]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.95it/s, acc=63.9, loss=15.5]\n",
      "[I 2025-03-29 20:32:41,817] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 Starting training...\n",
      "Model Parameters: threshold=0.010971910562600605, slope=9.684124178864082, beta=0.8675706240859451, p1=0.43472632110314163, p2=0.16861848847023486\n",
      "Optimizer Parameters: lr=1.3048565877454766e-05, weight_decay=4.3687525412335625e-05\n",
      "Scheduler Parameters: factor=0.2757105862290865, patience=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=72.7, loss=13.1]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.82it/s, acc=80, loss=9.93]  \n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=77.6, loss=10.9]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.02it/s, acc=79.4, loss=9.46]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.72it/s, acc=78, loss=10.5]  \n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.08it/s, acc=76.8, loss=12.5]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=77.6, loss=10.8]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.95it/s, acc=80.8, loss=9.47]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=78.5, loss=10.3]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.89it/s, acc=82.4, loss=7.97]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=79.5, loss=10.1]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.04it/s, acc=84.6, loss=7.91]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.80it/s, acc=79.6, loss=9.85]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.90it/s, acc=84.6, loss=8.4] \n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.81it/s, acc=79, loss=10]    \n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.27it/s, acc=80, loss=9.39]  \n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=79.6, loss=9.68]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.15it/s, acc=83.8, loss=8.1] \n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.81it/s, acc=80.8, loss=9.36]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s, acc=82.4, loss=8.8] \n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.74it/s, acc=80.8, loss=9.34]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.65it/s, acc=78.4, loss=10.2]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=78.8, loss=10.1]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.79it/s, acc=82, loss=9]     \n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.85it/s, acc=82.2, loss=8.9] \n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.00it/s, acc=83.2, loss=8.27]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=81.5, loss=8.98]\n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.91it/s, acc=81.8, loss=8.75]\n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=83.7, loss=8.4] \n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.02it/s, acc=83.2, loss=8.41]\n",
      "[I 2025-03-29 20:37:09,856] Trial 14 finished with value: 8.413565278053284 and parameters: {'threshold': 0.010971910562600605, 'slope': 9.684124178864082, 'beta': 0.8675706240859451, 'p1': 0.43472632110314163, 'p2': 0.16861848847023486, 'lr': 1.3048565877454766e-05, 'weight_decay': 4.3687525412335625e-05, 'scheduler_factor': 0.2757105862290865, 'scheduler_patience': 7}. Best is trial 3 with value: 7.678230956196785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Starting training...\n",
      "Model Parameters: threshold=0.025445597782387343, slope=14.285396248905599, beta=0.8373787045570488, p1=0.5323859553093591, p2=0.2946645736617323\n",
      "Optimizer Parameters: lr=4.467621546217666e-05, weight_decay=6.235726103303907e-06\n",
      "Scheduler Parameters: factor=0.4835745225633095, patience=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.78it/s, acc=72.2, loss=12.9]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.95it/s, acc=80.6, loss=8.75]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.61it/s, acc=79.4, loss=10.2]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.99it/s, acc=79.4, loss=9.88]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=81.1, loss=9.39]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.90it/s, acc=85.6, loss=8.42]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=81.6, loss=8.94]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.99it/s, acc=82.2, loss=8.93]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.62it/s, acc=82.1, loss=8.74]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.86it/s, acc=84.2, loss=7.83]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.66it/s, acc=83.7, loss=8.13]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.92it/s, acc=84.2, loss=8.01]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.75it/s, acc=83.3, loss=8.36]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.09it/s, acc=86, loss=7.12]  \n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=83.8, loss=8.23]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.96it/s, acc=83.2, loss=8.37]\n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=83.9, loss=7.92]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.94it/s, acc=84.6, loss=7.94]\n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=84.9, loss=7.71]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.83it/s, acc=86.2, loss=7.1] \n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.66it/s, acc=84.9, loss=7.77]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.86it/s, acc=86, loss=7.57]  \n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.73it/s, acc=85, loss=7.47]  \n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.86it/s, acc=86.4, loss=7.06]\n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.69it/s, acc=85, loss=7.53]  \n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.62it/s, acc=83.4, loss=8.14]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.69it/s, acc=84.7, loss=7.55]\n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s, acc=86, loss=7.57]  \n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.75it/s, acc=86.1, loss=7.21]\n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.07it/s, acc=85.4, loss=7.21]\n",
      "[I 2025-03-29 20:41:40,215] Trial 15 finished with value: 7.20956888794899 and parameters: {'threshold': 0.025445597782387343, 'slope': 14.285396248905599, 'beta': 0.8373787045570488, 'p1': 0.5323859553093591, 'p2': 0.2946645736617323, 'lr': 4.467621546217666e-05, 'weight_decay': 6.235726103303907e-06, 'scheduler_factor': 0.4835745225633095, 'scheduler_patience': 4}. Best is trial 15 with value: 7.20956888794899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 Starting training...\n",
      "Model Parameters: threshold=0.044402075414184304, slope=7.5818314324372, beta=0.8000021776506636, p1=0.5614477108692709, p2=0.30953982883336295\n",
      "Optimizer Parameters: lr=3.900982148101779e-05, weight_decay=5.728032536743455e-06\n",
      "Scheduler Parameters: factor=0.48479318664300713, patience=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.82it/s, acc=66.4, loss=15.9]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.71it/s, acc=74.9, loss=11.7]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.65it/s, acc=72, loss=12.7]  \n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.89it/s, acc=74.1, loss=12.1]\n",
      "[I 2025-03-29 20:42:16,299] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 Starting training...\n",
      "Model Parameters: threshold=0.02773502228620372, slope=13.910341934799977, beta=0.8335969601807178, p1=0.509462231505543, p2=0.2791970575929824\n",
      "Optimizer Parameters: lr=3.868370281118847e-05, weight_decay=7.0124488880615025e-06\n",
      "Scheduler Parameters: factor=0.35464070106770795, patience=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.70it/s, acc=67.3, loss=15.4]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.74it/s, acc=77.6, loss=10.4]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.63it/s, acc=77, loss=10.7]  \n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.70it/s, acc=82.6, loss=8.36]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=79.5, loss=9.73]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.74it/s, acc=83.4, loss=8.67]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.69it/s, acc=81.7, loss=8.88]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.00it/s, acc=82.8, loss=8.03]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=81.6, loss=8.88]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.85it/s, acc=84.6, loss=7.48]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=82, loss=8.86]  \n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.94it/s, acc=85.2, loss=7.49]\n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=82.6, loss=8.32]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.03it/s, acc=83.8, loss=8.01]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=84.1, loss=7.88]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.10it/s, acc=84.8, loss=7.37]\n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=83.8, loss=7.97]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.66it/s, acc=87, loss=6.66]  \n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.66it/s, acc=83.6, loss=7.97]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.95it/s, acc=86.2, loss=6.65]\n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.70it/s, acc=84.5, loss=7.71]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.64it/s, acc=86.8, loss=7.05]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=84.7, loss=7.68]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.68it/s, acc=88, loss=6.55]  \n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.65it/s, acc=84.6, loss=7.56]\n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.05it/s, acc=84.6, loss=7.54]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.74it/s, acc=85.1, loss=7.56]\n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.85it/s, acc=83.6, loss=8.41]\n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=84.8, loss=7.6] \n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.23it/s, acc=85.8, loss=7.48]\n",
      "[I 2025-03-29 20:46:46,908] Trial 17 finished with value: 7.477890536189079 and parameters: {'threshold': 0.02773502228620372, 'slope': 13.910341934799977, 'beta': 0.8335969601807178, 'p1': 0.509462231505543, 'p2': 0.2791970575929824, 'lr': 3.868370281118847e-05, 'weight_decay': 7.0124488880615025e-06, 'scheduler_factor': 0.35464070106770795, 'scheduler_patience': 8}. Best is trial 15 with value: 7.20956888794899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 Starting training...\n",
      "Model Parameters: threshold=0.026752887588159455, slope=13.706950900518262, beta=0.8350962208498997, p1=0.4228013011390916, p2=0.2694232353726885\n",
      "Optimizer Parameters: lr=3.985396625949444e-05, weight_decay=6.912131903513359e-06\n",
      "Scheduler Parameters: factor=0.3448843667608658, patience=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=68.2, loss=14.8]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.96it/s, acc=73.5, loss=13]  \n",
      "[I 2025-03-29 20:47:04,908] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 Starting training...\n",
      "Model Parameters: threshold=0.028847535823199398, slope=11.212417767597127, beta=0.8028692716337332, p1=0.5695640786292455, p2=0.20533050309435127\n",
      "Optimizer Parameters: lr=9.650258525175647e-05, weight_decay=8.77391783095112e-06\n",
      "Scheduler Parameters: factor=0.3171284013241936, patience=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.64it/s, acc=74.6, loss=12]  \n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.88it/s, acc=79.4, loss=10]  \n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=80.4, loss=9.21]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.81it/s, acc=81, loss=9.33]  \n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=82.7, loss=8.56]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.92it/s, acc=84.4, loss=7.25]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.71it/s, acc=82.1, loss=8.71]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.74it/s, acc=84.4, loss=7.8] \n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.62it/s, acc=78.4, loss=10.2]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.85it/s, acc=72.7, loss=12.5]\n",
      "Epoch 6/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.80it/s, acc=73, loss=12.7]  \n",
      "Epoch 6/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.99it/s, acc=71.5, loss=12]  \n",
      "Epoch 7/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.81it/s, acc=78, loss=10.3]  \n",
      "Epoch 7/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.96it/s, acc=83.4, loss=7.86]\n",
      "Epoch 8/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=80, loss=9.5]   \n",
      "Epoch 8/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.91it/s, acc=82.6, loss=8.29]\n",
      "Epoch 9/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.74it/s, acc=83.7, loss=8.19]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.18it/s, acc=85, loss=7.25]  \n",
      "Epoch 10/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.83it/s, acc=80.6, loss=9.11]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.11it/s, acc=87, loss=7.06]  \n",
      "Epoch 11/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.66it/s, acc=84.4, loss=7.8] \n",
      "Epoch 11/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.97it/s, acc=85.4, loss=7.19]\n",
      "Epoch 12/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.80it/s, acc=82.5, loss=8.3] \n",
      "Epoch 12/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.95it/s, acc=84, loss=7.87]  \n",
      "Epoch 13/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.79it/s, acc=83.8, loss=7.8] \n",
      "Epoch 13/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.02it/s, acc=85.4, loss=7.99]\n",
      "Epoch 14/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.77it/s, acc=84.1, loss=7.8] \n",
      "Epoch 14/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.88it/s, acc=84.6, loss=7.6] \n",
      "Epoch 15/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.72it/s, acc=84.6, loss=7.69]\n",
      "Epoch 15/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.85it/s, acc=86.4, loss=6.85]\n",
      "[I 2025-03-29 20:51:34,117] Trial 19 finished with value: 6.847384333610535 and parameters: {'threshold': 0.028847535823199398, 'slope': 11.212417767597127, 'beta': 0.8028692716337332, 'p1': 0.5695640786292455, 'p2': 0.20533050309435127, 'lr': 9.650258525175647e-05, 'weight_decay': 8.77391783095112e-06, 'scheduler_factor': 0.3171284013241936, 'scheduler_patience': 8}. Best is trial 19 with value: 6.847384333610535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Starting training...\n",
      "Model Parameters: threshold=0.018065884742655344, slope=10.918856879935474, beta=0.8065901386472965, p1=0.5784973356903819, p2=0.21146612672904203\n",
      "Optimizer Parameters: lr=9.312592112955676e-05, weight_decay=4.452296239024584e-06\n",
      "Scheduler Parameters: factor=0.30046513723188367, patience=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.72it/s, acc=60.7, loss=19.8]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00, 10.11it/s, acc=77.8, loss=11.5]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=73.8, loss=13.3]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.77it/s, acc=80, loss=10.5]  \n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.72it/s, acc=75.6, loss=11.8]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.68it/s, acc=72.5, loss=14.7]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.72it/s, acc=77, loss=11.3]  \n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.84it/s, acc=79.2, loss=10.1]\n",
      "[I 2025-03-29 20:52:46,390] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 Starting training...\n",
      "Model Parameters: threshold=0.029162809161686603, slope=14.272951377683057, beta=0.8409091510715602, p1=0.5094802748261659, p2=0.26405398135852215\n",
      "Optimizer Parameters: lr=3.289027157341665e-05, weight_decay=9.335546096084849e-06\n",
      "Scheduler Parameters: factor=0.3567690015168081, patience=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.67it/s, acc=71.9, loss=13.5]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.80it/s, acc=79.4, loss=10.1]\n",
      "Epoch 2/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.68it/s, acc=79.4, loss=10]  \n",
      "Epoch 2/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.81it/s, acc=83.4, loss=8.42]\n",
      "Epoch 3/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=80.8, loss=9.42]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.82it/s, acc=83.8, loss=8.39]\n",
      "Epoch 4/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.76it/s, acc=81.2, loss=9.04]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.86it/s, acc=85.6, loss=7.64]\n",
      "Epoch 5/15 [Train]: 100%|██████████| 110/110 [00:16<00:00,  6.61it/s, acc=82.4, loss=8.75]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 16/16 [00:01<00:00,  9.73it/s, acc=83.4, loss=8.27]\n",
      "Epoch 6/15 [Train]:  41%|████      | 45/110 [00:06<00:09,  6.78it/s, acc=83.5, loss=8.39]"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48878242",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

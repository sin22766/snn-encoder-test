{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1eae6e1-1cc0-406f-b59f-05ccf9a3efb4",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "First we will load the data that we prepare before using h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34d8c84-bd48-48c1-b761-d76559fdc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['channels', 'data', 'info']>\n",
      "<KeysViewHDF5 ['channels', 'data', 'info']>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "\n",
    "data_path = \"./CHB-MIT/processed\"\n",
    "ictal_path = os.path.join(data_path, \"ictal.h5\")\n",
    "interictal_path = os.path.join(data_path, \"interictal.h5\")\n",
    "\n",
    "ictal_file = h5py.File(ictal_path, 'r')\n",
    "interictal_file = h5py.File(interictal_path, 'r')\n",
    "\n",
    "print(ictal_file.keys())\n",
    "print(interictal_file.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba276b-794d-405a-9e42-dba6fa9c1e05",
   "metadata": {},
   "source": [
    "Since the info is the dictionary we need to convert it back from numpy_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a19680-ba7f-4805-9fd3-75594c64e7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'chb01_03.edf', 'start_time': 2996, 'end_time': 3004},\n",
       " {'file': 'chb01_03.edf', 'start_time': 3000, 'end_time': 3008}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "ictal_raw_info = ictal_file['info']\n",
    "interictal_raw_info = interictal_file['info']\n",
    "\n",
    "ictal_info = [ast.literal_eval(info_str.decode(\"utf-8\"))\n",
    "              for info_str in ictal_raw_info]\n",
    "interictal_info = [ast.literal_eval(info_str.decode(\n",
    "    \"utf-8\")) for info_str in interictal_raw_info]\n",
    "\n",
    "ictal_info[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27770eeb-e3e6-4776-9eb9-550172d3e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ictal data shape (2509, 22, 2048)\n",
      "Interictal data shape (2509, 22, 2048)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ictal_data = np.array(ictal_file['data'])\n",
    "interictal_data = np.array(interictal_file['data'])\n",
    "\n",
    "print(f\"Ictal data shape {ictal_data.shape}\")\n",
    "print(f\"Interictal data shape {interictal_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beeb7dce-189e-4b6a-b243-dcdff7ba2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, ictal_data, interictal_data):\n",
    "        self.data = torch.cat([ictal_data, interictal_data])  # Merge ictal & interictal\n",
    "        self.labels = torch.cat([\n",
    "            torch.ones(len(ictal_data)),  # Label 1 for ictal\n",
    "            torch.zeros(len(interictal_data))  # Label 0 for interictal\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_raw = self.data[idx]  # Raw EEG data, shape: (22, 2048)\n",
    "        label = self.labels[idx].long()\n",
    "        return eeg_raw, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ec354c-dc70-46ac-83d8-72998db48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "ictal_tensor = torch.tensor(ictal_data, dtype=torch.float32)\n",
    "interictal_tensor = torch.tensor(interictal_data, dtype=torch.float32)\n",
    "\n",
    "dataset = EEGDataset(ictal_tensor, interictal_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9acfe3c-0c7b-4afa-b20b-4096b18b0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-group55/.conda/envs/SeqSNN/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from SeqSNN.network import SpikeTemporalConvNet2D\n",
    "\n",
    "model = SpikeTemporalConvNet2D(\n",
    "    num_levels=4,  # Number of temporal layers (deeper for complex patterns)\n",
    "    channel=22,  # Number of EEG channels (for CHB-MIT or general EEG data)\n",
    "    dilation=2,  # Expands the receptive field to capture long-term dependencies\n",
    "    stride=1,  # Keep stride low to preserve temporal resolution\n",
    "    num_steps=16,  # Time steps for SNN processing (increase if more temporal info is needed)\n",
    "    kernel_size=3,  # Small kernel size to extract fine-grained EEG features\n",
    "    dropout=0.2,  # Regularization to prevent overfitting\n",
    "    max_length=4096,  # Maximum EEG sequence length (adjust based on dataset)\n",
    "    input_size=22,  # Input size (should match EEG channel count)\n",
    "    hidden_size=128,  # Sufficient neurons for feature learning\n",
    "    encoder_type=\"conv\",  # Convolutional encoder for spatial-temporal feature extraction\n",
    "    num_pe_neuron=10,  # Positional encoding neurons (for capturing phase-based seizure features)\n",
    "    pe_type=\"none\",  # No positional encoding (set to \"learned\" if needed)\n",
    "    pe_mode=\"concat\",  # Concatenates positional embeddings to input\n",
    "    neuron_pe_scale=1000.0,  # Scaling factor for encoding (depends on dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1c165-b8cd-4341-8ba8-44f5bf228388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Binary classification loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):  # Train for 10 epochs\n",
    "    print(f\"Start epoch {epoch}\")\n",
    "    total_loss = 0\n",
    "    for eeg_raw, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_spikes, final_spikes = model(eeg_raw)  # Model should handle encoding\n",
    "        loss = criterion(final_spikes, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeqSNN",
   "language": "python",
   "name": "seqsnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

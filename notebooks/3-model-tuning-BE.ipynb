{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa4224b-a6ff-43ce-a871-5d7378604317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload all\n",
    "\n",
    "%aimport -torch\n",
    "%aimport -matplotlib\n",
    "%aimport -seaborn\n",
    "%aimport -numpy\n",
    "%aimport -pandas\n",
    "%aimport -scipy\n",
    "%aimport -lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6c4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_snn_encoder.config import PROCESSED_DATA_DIR\n",
    "from eeg_snn_encoder.dataset import CHBMITDataset, CHBMITDataModule\n",
    "\n",
    "# Load the dataset\n",
    "dataset = CHBMITDataset(PROCESSED_DATA_DIR / \"stft_normalized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83601dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CHBMITDataModule(dataset, batch_size=768, worker=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e06ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from loguru import logger\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from eeg_snn_encoder.encoders import BurstEncoder\n",
    "from eeg_snn_encoder.models.classifier import ModelConfig\n",
    "from eeg_snn_encoder.models.lightning import LitSeizureClassifier, OptimizerConfig\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    model_params: ModelConfig = {\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "        \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "        \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "    }\n",
    "\n",
    "    optimizer_params: OptimizerConfig = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "    }\n",
    "\n",
    "    max_window = trial.suggest_int(\"max_window\", 4, 16)\n",
    "    n_max = trial.suggest_int(\"n_max\", 1, max_window)\n",
    "    t_max = trial.suggest_int(\"t_max\", 0, max_window // n_max)\n",
    "    t_min = trial.suggest_int(\"t_min\", 0, t_max)\n",
    "\n",
    "    encoder_params = {\n",
    "        \"max_window\": max_window,\n",
    "        \"n_max\": n_max,\n",
    "        \"t_max\": t_max,\n",
    "        \"t_min\": t_min,\n",
    "    }\n",
    "\n",
    "    spike_encoder = BurstEncoder(**encoder_params)\n",
    "    \n",
    "    lit_model = LitSeizureClassifier(\n",
    "        model_config=model_params,\n",
    "        optimizer_config=optimizer_params,\n",
    "        spike_encoder=spike_encoder,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        enable_model_summary=False,\n",
    "        enable_checkpointing=False,\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\"), EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)],\n",
    "        logger=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(lit_model, datamodule=datamodule)\n",
    "\n",
    "    val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "    \n",
    "    trainer.test(lit_model, datamodule=datamodule)\n",
    "\n",
    "    test_loss = trainer.callback_metrics[\"test_loss\"].item()\n",
    "    test_acc = trainer.callback_metrics[\"test_acc\"]\n",
    "    test_f1 = trainer.callback_metrics[\"test_f1\"]\n",
    "    test_mse = trainer.callback_metrics[\"test_mse\"]\n",
    "    test_total_spikes = trainer.callback_metrics[\"test_total_spikes\"]\n",
    "\n",
    "    logger.info(f\"Encoder: Burst Encoding,trial: {trial.number}, test_loss:{test_loss}, test_mse:{test_mse}, test_acc:{test_acc}, test_f1:{test_f1}, test_total_spikes:{test_total_spikes}\")\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292cc055",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 19:25:39,053] Using an existing study with name 'model-tuning-tbr' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialize the Optuna study\n",
    "sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"model-tuning-be\",\n",
    "    storage=os.environ[\"OPTUNA_CONN_STRING\"],\n",
    "    load_if_exists=True,\n",
    "    sampler=sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843b12b-d19f-4dd0-beb5-c1abb88ceaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c76e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 19:26:44.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mEncoder: TBR Encoding,trial, best_param: {'threshold': 0.0305685971329455, 'slope': 8.82839671962939, 'beta': 0.8562602268238131, 'dropout_rate1': 0.1605071202767286, 'dropout_rate2': 0.3320934135789956, 'lr': 3.922547202908979e-05, 'weight_decay': 3.174904373757126e-05, 'scheduler_factor': 0.9103134810378268, 'scheduler_patience': 7, 'tbr_threshold': 2}\u001b[0m\n",
      "\u001b[32m2025-05-06 19:26:45.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mEncoder: TBR Encoding,trial, best_score: 13.77458381652832\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Encoder: Burst Encoding,trial, best_param: {study.best_params}\")\n",
    "logger.info(f\"Encoder: Burst Encoding,trial, best_score: {study.best_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352d77b4-2cde-49f2-9eb2-97d6506bee39",
   "metadata": {},
   "source": [
    "# BSA encoder testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b3d62a-c626-4af4-aab4-e10004529f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CHBMITPreprocessedDataset\n",
    "\n",
    "dataset = CHBMITPreprocessedDataset('./CHB-MIT/processed_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282a93bd-2dfa-4979-89da-a190d6006286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478d3f13-6cf3-44be-9152-01f85de5cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from encoder import BSAEncoder\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"win_size\": trial.suggest_int(\"win_size\", 1, 16),\n",
    "        \"cutoff\": trial.suggest_float(\"cutoff\", 0.01, 1),\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 1),\n",
    "        \"normalize\": False\n",
    "    }\n",
    "\n",
    "    bsa_encoder = BSAEncoder(**params)\n",
    "\n",
    "    acc_se = []\n",
    "\n",
    "    val_loop = tqdm(data_loader, leave=False)\n",
    "    for idx, (data, _) in enumerate(val_loop):\n",
    "        data = data.to(device=\"cuda\")\n",
    "        encoded = bsa_encoder.encode(data)\n",
    "        decoded = bsa_encoder.decode(encoded)\n",
    "        del encoded\n",
    "        se = torch.mean((data - decoded) ** 2).item()\n",
    "        del data, decoded\n",
    "        acc_se.append(se)\n",
    "\n",
    "        intermediate_value = torch.tensor(acc_se).mean().item()\n",
    "\n",
    "        trial.report(intermediate_value, step=idx)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    mse = torch.tensor(acc_se).mean().item()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5b1f39-5863-4167-9f4e-d0b32589a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 23:42:31,133] Using an existing study with name 'BSA-tuning' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "from config import DB_CONN_STRING\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"BSA-tuning\",\n",
    "    storage=DB_CONN_STRING,\n",
    "    load_if_exists=True,\n",
    "    pruner=optuna.pruners.HyperbandPruner()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af102e12-03e8-46ee-8591-73166eee5544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 23:25:01,983] Trial 50 pruned.   \n",
      "[I 2025-04-29 23:25:02,593] Trial 51 pruned.   \n",
      "[I 2025-04-29 23:25:03,143] Trial 52 pruned.   \n",
      "[I 2025-04-29 23:25:03,500] Trial 53 pruned.   \n",
      "[I 2025-04-29 23:25:04,163] Trial 54 pruned.   \n",
      "[I 2025-04-29 23:25:04,517] Trial 55 pruned.   \n",
      "[I 2025-04-29 23:25:04,867] Trial 56 pruned.   \n",
      "[I 2025-04-29 23:25:05,906] Trial 57 pruned.    \n",
      "[I 2025-04-29 23:25:06,286] Trial 58 pruned.   \n",
      "[I 2025-04-29 23:25:07,351] Trial 59 pruned.    \n",
      "[I 2025-04-29 23:25:09,885] Trial 60 pruned.    \n",
      "[I 2025-04-29 23:25:10,259] Trial 61 pruned.   \n",
      "[I 2025-04-29 23:25:14,783] Trial 62 finished with value: 0.029187312349677086 and parameters: {'win_size': 6, 'cutoff': 0.24976747334792332, 'threshold': 0.3258294527482926}. Best is trial 16 with value: 0.028090717270970345.\n",
      "[I 2025-04-29 23:25:15,804] Trial 63 pruned.    \n",
      "[I 2025-04-29 23:25:16,177] Trial 64 pruned.   \n",
      "[I 2025-04-29 23:25:20,755] Trial 65 finished with value: 0.0301541555672884 and parameters: {'win_size': 6, 'cutoff': 0.3763826554195012, 'threshold': 0.4163259864672635}. Best is trial 16 with value: 0.028090717270970345.\n",
      "[I 2025-04-29 23:25:25,338] Trial 66 finished with value: 0.028089215978980064 and parameters: {'win_size': 5, 'cutoff': 0.1717529137198048, 'threshold': 0.36060847904230925}. Best is trial 66 with value: 0.028089215978980064.\n",
      "[I 2025-04-29 23:25:25,755] Trial 67 pruned.   \n",
      "[I 2025-04-29 23:25:26,149] Trial 68 pruned.   \n",
      "[I 2025-04-29 23:25:26,581] Trial 69 pruned.   \n",
      "[I 2025-04-29 23:25:27,010] Trial 70 pruned.   \n",
      "[I 2025-04-29 23:25:27,445] Trial 71 pruned.   \n",
      "[I 2025-04-29 23:25:27,886] Trial 72 pruned.   \n",
      "[I 2025-04-29 23:25:29,010] Trial 73 pruned.    \n",
      "[I 2025-04-29 23:25:29,362] Trial 74 pruned.   \n",
      "[I 2025-04-29 23:25:29,969] Trial 75 pruned.   \n",
      "[I 2025-04-29 23:25:30,360] Trial 76 pruned.   \n",
      "[I 2025-04-29 23:25:30,734] Trial 77 pruned.   \n",
      "[I 2025-04-29 23:25:31,107] Trial 78 pruned.   \n",
      "[I 2025-04-29 23:25:32,213] Trial 79 pruned.    \n",
      "[I 2025-04-29 23:25:32,652] Trial 80 pruned.   \n",
      "[I 2025-04-29 23:25:33,257] Trial 81 pruned.   \n",
      "[I 2025-04-29 23:25:33,696] Trial 82 pruned.   \n",
      "[I 2025-04-29 23:25:34,140] Trial 83 pruned.   \n",
      "[I 2025-04-29 23:25:38,888] Trial 84 finished with value: 0.0285087451338768 and parameters: {'win_size': 5, 'cutoff': 0.16822946710463704, 'threshold': 0.30771550062212255}. Best is trial 66 with value: 0.028089215978980064.\n",
      "[I 2025-04-29 23:25:43,415] Trial 85 finished with value: 0.027979398146271706 and parameters: {'win_size': 5, 'cutoff': 0.0783798427188899, 'threshold': 0.34573537837121776}. Best is trial 85 with value: 0.027979398146271706.\n",
      "[I 2025-04-29 23:25:44,370] Trial 86 pruned.    \n",
      "[I 2025-04-29 23:25:44,728] Trial 87 pruned.   \n",
      "[I 2025-04-29 23:25:45,118] Trial 88 pruned.   \n",
      "[I 2025-04-29 23:25:45,530] Trial 89 pruned.   \n",
      "[I 2025-04-29 23:25:46,088] Trial 90 pruned.   \n",
      "[I 2025-04-29 23:25:48,671] Trial 91 pruned.    \n",
      "[I 2025-04-29 23:25:49,068] Trial 92 pruned.   \n",
      "[I 2025-04-29 23:25:49,418] Trial 93 pruned.   \n",
      "[I 2025-04-29 23:25:49,781] Trial 94 pruned.   \n",
      "[I 2025-04-29 23:25:50,253] Trial 95 pruned.   \n",
      "[I 2025-04-29 23:25:50,604] Trial 96 pruned.   \n",
      "[I 2025-04-29 23:25:55,371] Trial 97 finished with value: 0.027217740193009377 and parameters: {'win_size': 2, 'cutoff': 0.5972354781083807, 'threshold': 0.3006922907578217}. Best is trial 97 with value: 0.027217740193009377.\n",
      "[I 2025-04-29 23:25:59,913] Trial 98 finished with value: 0.027249567210674286 and parameters: {'win_size': 2, 'cutoff': 0.6037344524096372, 'threshold': 0.30419479032281105}. Best is trial 97 with value: 0.027217740193009377.\n",
      "[I 2025-04-29 23:26:00,282] Trial 99 pruned.   \n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

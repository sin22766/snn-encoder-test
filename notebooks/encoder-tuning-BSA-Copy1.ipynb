{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352d77b4-2cde-49f2-9eb2-97d6506bee39",
   "metadata": {},
   "source": [
    "# BSA encoder testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5fc621-4f64-43c6-baf6-67f2ce78c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CHBMITDataset\n",
    "\n",
    "data_path = \"./CHB-MIT/processed\"\n",
    "dataset = CHBMITDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4af7b5-7143-45ef-9ab8-863fb2f7cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils.preprocess import VectorizeSTFT\n",
    "\n",
    "\n",
    "def normalize(x: torch.Tensor) -> torch.Tensor:\n",
    "    x_min = x.min(dim=-1, keepdim=True).values\n",
    "    x_max = x.max(dim=-1, keepdim=True).values\n",
    "\n",
    "    diff = x_max - x_min\n",
    "    diff[diff == 0] = 1.0\n",
    "\n",
    "    return (x - x_min) / diff\n",
    "\n",
    "\n",
    "def preprocess_data(x: torch.Tensor) -> torch.Tensor:\n",
    "    stft_data = VectorizeSTFT(x)\n",
    "    magnitudes = torch.abs(stft_data)\n",
    "    normalized = normalize(magnitudes)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a33ed2-e2c3-4930-953c-98c4b050fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PreparedDataset(Dataset):\n",
    "    def __init__(self, dataset: CHBMITDataset) -> None:\n",
    "        data = preprocess_data(dataset.data.to(device=\"cuda\"))\n",
    "        self.data = data\n",
    "        self.labels = dataset.labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        eeg_raw = self.data[idx]  # EEG data of shape (22, 2048)\n",
    "        label = self.labels[idx].bool()  # Label: 0 (interictal) or 1 (ictal)\n",
    "        return eeg_raw, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b3d62a-c626-4af4-aab4-e10004529f15",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid configuration argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from torch.utils.data import DataLoader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m prepared_dataset = \u001b[43mPreparedDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m dataset\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# data_loader = DataLoader(prepared_dataset, batch_size=1024, shuffle=True, num_workers=8)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mPreparedDataset.__init__\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: CHBMITDataset) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     data = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mself\u001b[39m.labels = dataset.labels\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_data\u001b[39m(x: torch.Tensor) -> torch.Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     stft_data = \u001b[43mVectorizeSTFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     magnitudes = torch.abs(stft_data)\n\u001b[32m     19\u001b[39m     normalized = normalize(magnitudes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snn-encoder-test/utils/preprocess.py:25\u001b[39m, in \u001b[36mVectorizeSTFT\u001b[39m\u001b[34m(eeg_data, n_fft, hop_length, win_length)\u001b[39m\n\u001b[32m     22\u001b[39m reshaped_data = eeg_data.reshape(-\u001b[32m1\u001b[39m, time_steps)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Apply STFT to all channels at once\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m stft = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreshaped_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Reshape back to (batch, channels, freq_bins, time_frames)\u001b[39;00m\n\u001b[32m     35\u001b[39m _, freq_bins, time_frames = stft.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/functional.py:707\u001b[39m, in \u001b[36mstft\u001b[39m\u001b[34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[39m\n\u001b[32m    705\u001b[39m     extended_shape = [\u001b[32m1\u001b[39m] * (\u001b[32m3\u001b[39m - signal_dim) + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m    706\u001b[39m     pad = \u001b[38;5;28mint\u001b[39m(n_fft // \u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextended_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m.view(\u001b[38;5;28minput\u001b[39m.shape[-signal_dim:])\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _VF.stft(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    710\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    711\u001b[39m     n_fft,\n\u001b[32m   (...)\u001b[39m\u001b[32m    717\u001b[39m     return_complex,\n\u001b[32m    718\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/functional.py:5209\u001b[39m, in \u001b[36mpad\u001b[39m\u001b[34m(input, pad, mode, value)\u001b[39m\n\u001b[32m   5202\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mreplicate\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   5203\u001b[39m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[32m   5204\u001b[39m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[32m   5205\u001b[39m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[32m   5206\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\n\u001b[32m   5207\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtorch._decomp.decompositions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5208\u001b[39m             )._replication_pad(\u001b[38;5;28minput\u001b[39m, pad)\n\u001b[32m-> \u001b[39m\u001b[32m5209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: invalid configuration argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "prepared_dataset = PreparedDataset(dataset)\n",
    "del dataset\n",
    "# data_loader = DataLoader(prepared_dataset, batch_size=1024, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478d3f13-6cf3-44be-9152-01f85de5cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from encoder import BSAEncoder\n",
    "from utils.snr import SNRCalculator\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"win_size\": trial.suggest_int(\"win_size\", 1, 16),\n",
    "        \"cutoff\": trial.suggest_float(\"cutoff\", 0.01, 0.99),\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.99),\n",
    "    }\n",
    "\n",
    "    bsa_encoder = BSAEncoder(**params)\n",
    "\n",
    "    batch_size = 32  # or whatever fits\n",
    "    decoded_batches = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode the whole dataset ONCE\n",
    "        encoded_data = bsa_encoder.encode(prepared_dataset.data)\n",
    "\n",
    "        # Now batch only the decoding\n",
    "        for start in range(0, encoded_data.size(0), batch_size):\n",
    "            end = min(start + batch_size, encoded_data.size(0))\n",
    "            encoded_batch = encoded_data[start:end]\n",
    "\n",
    "            decoded_batch = bsa_encoder.decode(encoded_batch)\n",
    "            decoded_batches.append(decoded_batch)\n",
    "\n",
    "    # After all decoding is done, concatenate\n",
    "    all_decoded = torch.cat(decoded_batches, dim=0)\n",
    "\n",
    "    snr = SNRCalculator.calculate_overall_snr(encoded_data, all_decoded)\n",
    "    # # Final MSE\n",
    "    # mse = torch.nn.functional.mse_loss(all_decoded, prepared_dataset.data).item()\n",
    "    # return mse\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5b1f39-5863-4167-9f4e-d0b32589a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 00:46:04,333] Using an existing study with name 'BSA SNR metric' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "from config import DB_CONN_STRING\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"BSA SNR metric\",\n",
    "    storage=DB_CONN_STRING,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "# study = optuna.create_study(\n",
    "#     direction=\"minimize\",\n",
    "#     study_name=\"BSA mse Memory test\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af102e12-03e8-46ee-8591-73166eee5544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 00:46:33,568] Trial 11 finished with value: 0.6063430309295654 and parameters: {'win_size': 5, 'cutoff': 0.26505247213031147, 'threshold': 0.5021550717154726}. Best is trial 6 with value: 0.8596798181533813.\n",
      "[I 2025-04-29 00:47:23,823] Trial 12 finished with value: -1.2047570943832397 and parameters: {'win_size': 12, 'cutoff': 0.6882673778640046, 'threshold': 0.7442478075180808}. Best is trial 6 with value: 0.8596798181533813.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf9a11-e458-4cbe-8a06-ff3577444a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad7d77-5a4a-486a-b20d-c72248330d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

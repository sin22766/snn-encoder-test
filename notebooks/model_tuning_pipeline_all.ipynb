{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cc7af7-5ca2-4964-9014-2001d1f6eca9",
   "metadata": {},
   "source": [
    "# Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de033f",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Load the preprocessed data which prepared in HDF5 format. The data is split into training, validation, and test sets. The training set is used to train the model, the validation set is used to tune the hyperparameters, and the test set is used to evaluate the final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77bd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CHBMITPreprocessedDataset\n",
    "\n",
    "dataset = CHBMITPreprocessedDataset('./CHB-MIT/processed_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ecb71-7087-4c20-bd5d-e238c484ae76",
   "metadata": {},
   "source": [
    "## Assemble the model\n",
    "\n",
    "We will use the Pytorch Lightning library to build the model pipeline from the based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2acee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.lightning import CHBMITPreprocessedDataModule\n",
    "\n",
    "datamodule = CHBMITPreprocessedDataModule(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24755af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from encoder import StepForwardEncoder\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from model.classifier import ModelConfig\n",
    "from model.lightning import OptimizerConfig, LitSTFTPreprocessedSeizureClassifier\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "def objective_sf(trial: optuna.trial.Trial) -> float:\n",
    "    model_params: ModelConfig = {\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "        \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "        \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "    }\n",
    "\n",
    "    optimizer_params: OptimizerConfig = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "    }\n",
    "    encoder_threshold = trial.suggest_float(\"encoder_threshold\", 0.1, 0.99, log=True)\n",
    "    \n",
    "    spike_encoder = StepForwardEncoder(threshold=encoder_threshold, normalize=False)\n",
    "\n",
    "    model = LitSTFTPreprocessedSeizureClassifier(\n",
    "        model_config=model_params,\n",
    "        optimizer_config=optimizer_params,\n",
    "        spike_encoder=spike_encoder,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=15,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d5cf32-5a13-441e-bc01-98b11e1c488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from encoder import BSAEncoder\n",
    "\n",
    "\n",
    "def objective_bsa(trial: optuna.trial.Trial) -> float:\n",
    "    model_params: ModelConfig = {\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "        \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "        \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "    }\n",
    "\n",
    "    optimizer_params: OptimizerConfig = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "    }\n",
    "    params = {\n",
    "        \"win_size\": trial.suggest_int(\"win_size\", 1, 16),\n",
    "        \"cutoff\": trial.suggest_float(\"cutoff\", 0.01, 1),\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 1),\n",
    "        \"normalize\": False\n",
    "    }\n",
    "    \n",
    "    spike_encoder = BSAEncoder(**params)\n",
    "\n",
    "    model = LitSTFTPreprocessedSeizureClassifier(\n",
    "        model_config=model_params,\n",
    "        optimizer_config=optimizer_params,\n",
    "        spike_encoder=spike_encoder,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=15,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70c42ae-5234-4f35-87ba-f228d245acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from encoder import PhaseEncoderExpand\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from model.classifier import ModelConfig\n",
    "from model.lightning import OptimizerConfig, LitSTFTPreprocessedSeizureClassifier\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "def objective_pe(trial: optuna.trial.Trial) -> float:\n",
    "    model_params: ModelConfig = {\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "        \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "        \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "    }\n",
    "\n",
    "    optimizer_params: OptimizerConfig = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "    }\n",
    "    params = {\n",
    "        \"phase_window\": trial.suggest_int(\"phase_window\", 1, 16),\n",
    "        \"normalize\": False\n",
    "    }\n",
    "\n",
    "    spike_encoder = PhaseEncoderExpand(**params)\n",
    "\n",
    "    model = LitSTFTPreprocessedSeizureClassifier(\n",
    "        model_config=model_params,\n",
    "        optimizer_config=optimizer_params,\n",
    "        spike_encoder=spike_encoder,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=15,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53dd58c1-4018-4074-828e-ffa531a08b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DB_CONN_STRING\n",
    "import optuna\n",
    "\n",
    "def create_and_run_study(study_name: str, objective, n_trials: int):\n",
    "\n",
    "    sampler = optuna.samplers.CmaEsSampler()\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=study_name,\n",
    "        sampler=sampler,\n",
    "        storage=DB_CONN_STRING,\n",
    "        load_if_exists=True,\n",
    "        pruner=optuna.pruners.HyperbandPruner()\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695a3beb-5ca2-443f-917e-ca334634fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\n",
    "    (\"Classifier_SF_Tuning\", objective_sf, 100),\n",
    "    (\"Classifier_BSA_Tuning\", objective_bsa, 100),\n",
    "    (\"Classifier_PE_Tuning\", objective_pe, 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 01:46:49,388] A new study created in RDB with name: Classifier_SF_Tuning\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type               | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model | EEGSpikeClassifier | 824 K  | train\n",
      "-----------------------------------------------------\n",
      "824 K     Trainable params\n",
      "0         Non-trainable params\n",
      "824 K     Total params\n",
      "3.299     Total estimated model params size (MB)\n",
      "13        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d8199d97d247bc88dfd0c7199c2d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7803afd7ea6d42a7a1eda9b96ceb0521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147b5a8ac048421f942df4e032b758f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524ad17ec32d47038496ae8e521988b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80f03cb1667401b9fcc2056def6957c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233984227b284a4489d274996701de9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, objective_fn, n_trials in experiment:\n",
    "    create_and_run_study(name, objective_fn, n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffea26-85b2-43a5-8197-9a476e52e9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

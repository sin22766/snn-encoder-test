{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa4224b-a6ff-43ce-a871-5d7378604317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload all\n",
    "\n",
    "%aimport -torch\n",
    "%aimport -matplotlib\n",
    "%aimport -seaborn\n",
    "%aimport -numpy\n",
    "%aimport -pandas\n",
    "%aimport -scipy\n",
    "%aimport -lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58ebcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 02:01:24.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36meeg_snn_encoder.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: E:\\Projects\\snn-encoder-test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "\n",
    "from eeg_snn_encoder.config import PROCESSED_DATA_DIR\n",
    "from eeg_snn_encoder.dataset import CHBMITDataset\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6c4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = CHBMITDataset(PROCESSED_DATA_DIR / \"stft_normalized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83601dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "generator = torch.manual_seed(47)\n",
    "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2cccbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292cc055",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_list = [\n",
    "    \"be\",\n",
    "    \"pe\",\n",
    "    \"poisson\",\n",
    "    \"bsa\",\n",
    "    \"sf\",\n",
    "    \"tbr\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fcd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eeg_snn_encoder.tuning import ENCODER_TUNING_FUNCTIONS\n",
    "\n",
    "\n",
    "def create_encoder_objective(encoder_type: str):\n",
    "    if encoder_type not in ENCODER_TUNING_FUNCTIONS:\n",
    "        valid_types = list(ENCODER_TUNING_FUNCTIONS.keys())\n",
    "        raise ValueError(f\"Unsupported encoder type: {encoder_type}. Choose from: {valid_types}\")\n",
    "\n",
    "    def objective(trial: optuna.Trial):\n",
    "        encoder = ENCODER_TUNING_FUNCTIONS[encoder_type](trial)\n",
    "\n",
    "        data = tqdm(train_loader, desc=f\"Training {encoder_type} encoder\", leave=False)\n",
    "\n",
    "        loss_sum = 0\n",
    "        batch_count = 0\n",
    "\n",
    "\n",
    "        for idx, batch in enumerate(data):\n",
    "            x, y = batch\n",
    "            x = x.to(device=\"cuda\")\n",
    "            y = y.to(device=\"cuda\")\n",
    "\n",
    "            # Forward pass\n",
    "            encoded_data = encoder(x)\n",
    "\n",
    "            decoded_params = encoder.get_decode_params(x)\n",
    "\n",
    "            decoded_data = encoder.decode(encoded_data, decoded_params)\n",
    "\n",
    "            # Compute rmse\n",
    "            squared_error = torch.sum((decoded_data - x) ** 2)\n",
    "\n",
    "            loss_sum += squared_error.item()\n",
    "            batch_count += x.numel()\n",
    "        \n",
    "        # Compute the average loss\n",
    "        avg_loss = loss_sum / batch_count\n",
    "        rmse = math.sqrt(avg_loss)\n",
    "        \n",
    "        return rmse\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3e7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 02:17:04.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mStarting tuning encoder for be\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'OPTUNA_CONN_STRING_CPE'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      8\u001b[39m sampler = optuna.samplers.TPESampler()\n\u001b[32m     10\u001b[39m pruner = optuna.pruners.HyperbandPruner()\n\u001b[32m     12\u001b[39m study = optuna.create_study(\n\u001b[32m     13\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     study_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mencoder-tuning-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtuning\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     storage=\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPTUNA_CONN_STRING_CPE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     16\u001b[39m     load_if_exists=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     17\u001b[39m     sampler=sampler,\n\u001b[32m     18\u001b[39m     pruner=pruner,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m objective = create_encoder_objective(tuning)\n\u001b[32m     23\u001b[39m study.optimize(objective, n_trials=\u001b[32m500\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:714\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'OPTUNA_CONN_STRING_CPE'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "for tuning in tuning_list:\n",
    "    logger.info(f\"Starting tuning encoder for {tuning}\")\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "    pruner = optuna.pruners.HyperbandPruner()\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=f\"encoder-tuning-{tuning}\",\n",
    "        storage=os.environ[\"OPTUNA_CONN_STRING_CPE\"],\n",
    "        load_if_exists=True,\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "    )\n",
    "\n",
    "    objective = create_encoder_objective(tuning)\n",
    "\n",
    "    study.optimize(objective, n_trials=500)\n",
    "\n",
    "    logger.info(f\"Finished tuning encoder for {tuning}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

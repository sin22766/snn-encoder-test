{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cc7af7-5ca2-4964-9014-2001d1f6eca9",
   "metadata": {},
   "source": [
    "# Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de033f",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Load the preprocessed data which prepared in HDF5 format. The data is split into training, validation, and test sets. The training set is used to train the model, the validation set is used to tune the hyperparameters, and the test set is used to evaluate the final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77bd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CHBMITPreprocessedDataset\n",
    "\n",
    "dataset = CHBMITPreprocessedDataset('./CHB-MIT/processed_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ecb71-7087-4c20-bd5d-e238c484ae76",
   "metadata": {},
   "source": [
    "## Assemble the model\n",
    "\n",
    "We will use the Pytorch Lightning library to build the model pipeline from the based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2acee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.lightning import CHBMITPreprocessedDataModule\n",
    "\n",
    "datamodule = CHBMITPreprocessedDataModule(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24755af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from encoder import TBREncoder\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from model.classifier import ModelConfig\n",
    "from model.lightning import OptimizerConfig, LitSTFTPreprocessedSeizureClassifier\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "def objective_tbr(trial: optuna.trial.Trial) -> float:\n",
    "    model_params: ModelConfig = {\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "        \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "        \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "    }\n",
    "\n",
    "    optimizer_params: OptimizerConfig = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "    }\n",
    "    encoder_threshold = trial.suggest_float(\"encoder_threshold\", 0.1, 0.99, log=True)\n",
    "    \n",
    "    spike_encoder = TBREncoder(threshold=encoder_threshold, normalize=False)\n",
    "\n",
    "    model = LitSTFTPreprocessedSeizureClassifier(\n",
    "        model_config=model_params,\n",
    "        optimizer_config=optimizer_params,\n",
    "        spike_encoder=spike_encoder,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=15,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d5cf32-5a13-441e-bc01-98b11e1c488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from encoder import PoissonEncoder\n",
    "# from optuna.integration import PyTorchLightningPruningCallback\n",
    "# from model.classifier import ModelConfig\n",
    "# from model.lightning import OptimizerConfig, LitSTFTPreprocessedSeizureClassifier\n",
    "# import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "# def objective_rate(trial: optuna.trial.Trial) -> float:\n",
    "#     model_params: ModelConfig = {\n",
    "#         \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "#         \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "#         \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "#         \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "#         \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "#     }\n",
    "\n",
    "#     optimizer_params: OptimizerConfig = {\n",
    "#         \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "#         \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "#         \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "#         \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "#     }\n",
    "#     params = {\n",
    "#         \"interval_freq\": trial.suggest_int(\"interval_freq\", 1, 16),\n",
    "#         \"normalize\": False\n",
    "#     }\n",
    "\n",
    "#     spike_encoder = PoissonEncoder(**params)\n",
    "\n",
    "#     model = LitSTFTPreprocessedSeizureClassifier(\n",
    "#         model_config=model_params,\n",
    "#         optimizer_config=optimizer_params,\n",
    "#         spike_encoder=spike_encoder,\n",
    "#     )\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=15,\n",
    "#         accelerator=\"auto\",\n",
    "#         devices=\"auto\",\n",
    "#         strategy=\"auto\",\n",
    "#         callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "#     )\n",
    "\n",
    "#     trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "#     return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70c42ae-5234-4f35-87ba-f228d245acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from encoder import BurstEncoder\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from model.classifier import ModelConfig\n",
    "from model.lightning import OptimizerConfig, LitSTFTPreprocessedSeizureClassifier\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "def objective_be(trial: optuna.trial.Trial) -> float:\n",
    "    model_params: ModelConfig = {\n",
    "        \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "        \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "        \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "        \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "        \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "    }\n",
    "\n",
    "    optimizer_params: OptimizerConfig = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "        \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "        \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "    }\n",
    "    t_min = trial.suggest_int(\"t_min\", 1, 16)\n",
    "    t_max = trial.suggest_int(\"t_max\", t_min, 16)\n",
    "\n",
    "    params = {\n",
    "        \"max_window\": trial.suggest_int(\"max_window\", 1, 16),\n",
    "        \"n_max\": trial.suggest_int(\"n_max\", 1, 16),\n",
    "        \"t_min\": t_min,\n",
    "        \"t_max\": t_max,\n",
    "        \"normalize\": False\n",
    "    }\n",
    "\n",
    "\n",
    "    spike_encoder = BurstEncoder(**params)\n",
    "\n",
    "    model = LitSTFTPreprocessedSeizureClassifier(\n",
    "        model_config=model_params,\n",
    "        optimizer_config=optimizer_params,\n",
    "        spike_encoder=spike_encoder,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=15,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b94359-a16b-467f-8c92-5432b08ebac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from encoder import DummyEncoder\n",
    "# from optuna.integration import PyTorchLightningPruningCallback\n",
    "# from model.classifier import ModelConfig\n",
    "# from model.lightning import OptimizerConfig, LitSTFTPreprocessedSeizureClassifier\n",
    "# import lightning.pytorch as pl\n",
    "\n",
    "\n",
    "# def objective_base(trial: optuna.trial.Trial) -> float:\n",
    "#     model_params: ModelConfig = {\n",
    "#         \"threshold\": trial.suggest_float(\"threshold\", 0.01, 0.5),\n",
    "#         \"slope\": trial.suggest_float(\"slope\", 1.0, 20.0),\n",
    "#         \"beta\": trial.suggest_float(\"beta\", 0.1, 0.99),\n",
    "#         \"dropout_rate1\": trial.suggest_float(\"dropout_rate1\", 0.1, 0.99),\n",
    "#         \"dropout_rate2\": trial.suggest_float(\"dropout_rate2\", 0.1, 0.99),\n",
    "#     }\n",
    "\n",
    "#     optimizer_params: OptimizerConfig = {\n",
    "#         \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True),\n",
    "#         \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True),\n",
    "#         \"scheduler_factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.99),\n",
    "#         \"scheduler_patience\": trial.suggest_int(\"scheduler_patience\", 1, 10),\n",
    "#     }\n",
    "\n",
    "#     spike_encoder = DummyEncoder()\n",
    "\n",
    "#     model = LitSTFTPreprocessedSeizureClassifier(\n",
    "#         model_config=model_params,\n",
    "#         optimizer_config=optimizer_params,\n",
    "#         spike_encoder=spike_encoder,\n",
    "#     )\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=15,\n",
    "#         accelerator=\"auto\",\n",
    "#         devices=\"auto\",\n",
    "#         strategy=\"auto\",\n",
    "#         callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "#     )\n",
    "\n",
    "#     trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "#     return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53dd58c1-4018-4074-828e-ffa531a08b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DB_CONN_STRING\n",
    "import optuna\n",
    "\n",
    "def create_and_run_study(study_name: str, objective, n_trials: int):\n",
    "\n",
    "    sampler = optuna.samplers.CmaEsSampler()\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=study_name,\n",
    "        sampler=sampler,\n",
    "        storage=DB_CONN_STRING,\n",
    "        load_if_exists=True,\n",
    "        pruner=optuna.pruners.HyperbandPruner()\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695a3beb-5ca2-443f-917e-ca334634fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\n",
    "    (\"Classifier_TBR_Tuning\", objective_tbr, 100)\n",
    "    # (\"Classifier_BE_Tuning\", objective_be, 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa5dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-02 14:21:22,086] Using an existing study with name 'Classifier_TBR_Tuning' instead of creating a new one.\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[W 2025-05-02 14:21:22,533] Trial 8 failed with parameters: {'threshold': 0.24047997338687024, 'slope': 10.527643800292791, 'beta': 0.37752429156045253, 'dropout_rate1': 0.9104056643270606, 'dropout_rate2': 0.863434987819242, 'lr': 9.963619780768693e-06, 'weight_decay': 1.066786004768632e-05, 'scheduler_factor': 0.6025902109938148, 'scheduler_patience': 7, 'encoder_threshold': 0.5383026217340711} because of the following error: RuntimeError('CUDA error: CUDA-capable device(s) is/are busy or unavailable\\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3880877/292721773.py\", line 42, in objective_tbr\n",
      "    trainer.fit(model, datamodule=datamodule)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 988, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py\", line 155, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/pytorch/strategies/single_device.py\", line 79, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/lightning/fabric/utilities/device_dtype_mixin.py\", line 55, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1343, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 930, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/jupyter-group55/.local/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1329, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "RuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[W 2025-05-02 14:21:22,535] Trial 8 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, objective_fn, n_trials \u001b[38;5;129;01min\u001b[39;00m experiment:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mcreate_and_run_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcreate_and_run_study\u001b[39m\u001b[34m(study_name, objective, n_trials)\u001b[39m\n\u001b[32m      6\u001b[39m sampler = optuna.samplers.CmaEsSampler()\n\u001b[32m      7\u001b[39m study = optuna.create_study(\n\u001b[32m      8\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     study_name=study_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     pruner=optuna.pruners.HyperbandPruner()\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mobjective_tbr\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     28\u001b[39m model = LitSTFTPreprocessedSeizureClassifier(\n\u001b[32m     29\u001b[39m     model_config=model_params,\n\u001b[32m     30\u001b[39m     optimizer_config=optimizer_params,\n\u001b[32m     31\u001b[39m     spike_encoder=spike_encoder,\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m trainer = pl.Trainer(\n\u001b[32m     35\u001b[39m     max_epochs=\u001b[32m15\u001b[39m,\n\u001b[32m     36\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     callbacks=[PyTorchLightningPruningCallback(trial, monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m     40\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trainer.callback_metrics[\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m].item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:988\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.reset_metrics()\n\u001b[32m    987\u001b[39m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:155\u001b[39m, in \u001b[36mStrategy.setup\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# let the precision plugin convert the module here so that this strategy hook can decide the order\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# of operations\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.precision_plugin.convert_module(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._setup_model(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/pytorch/strategies/single_device.py:79\u001b[39m, in \u001b[36mSingleDeviceStrategy.model_to_device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mself.model must be set before self.model.to()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/lightning/fabric/utilities/device_dtype_mixin.py:55\u001b[39m, in \u001b[36m_DeviceDtypeModuleMixin.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m device, dtype = torch._C._nn._parse_to(*args, **kwargs)[:\u001b[32m2\u001b[39m]\n\u001b[32m     54\u001b[39m _update_properties(\u001b[38;5;28mself\u001b[39m, device=device, dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1329\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1323\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1324\u001b[39m             device,\n\u001b[32m   1325\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1326\u001b[39m             non_blocking,\n\u001b[32m   1327\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1328\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for name, objective_fn, n_trials in experiment:\n",
    "    create_and_run_study(name, objective_fn, n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffea26-85b2-43a5-8197-9a476e52e9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

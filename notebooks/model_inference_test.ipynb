{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155dbc3e-e144-412c-b1a2-0e9abc65dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ef0d2a-727b-4290-908e-d73a190337d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['channels', 'data', 'info']>\n",
      "<KeysViewHDF5 ['channels', 'data', 'info']>\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./CHB-MIT/processed\"\n",
    "ictal_path = os.path.join(data_path, \"ictal.h5\")\n",
    "interictal_path = os.path.join(data_path, \"interictal.h5\")\n",
    "\n",
    "ictal_file = h5py.File(ictal_path, 'r')\n",
    "interictal_file = h5py.File(interictal_path, 'r')\n",
    "\n",
    "print(ictal_file.keys())\n",
    "print(interictal_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb10b45d-4775-4883-8db4-3b8d1063cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ictal data shape torch.Size([2509, 22, 2048])\n",
      "Interictal data shape torch.Size([2509, 22, 2048])\n"
     ]
    }
   ],
   "source": [
    "ictal_np = np.array(ictal_file['data'])\n",
    "interictal_np = np.array(interictal_file['data'])\n",
    "\n",
    "ictal_data = torch.tensor(ictal_np, dtype=torch.float32)\n",
    "interictal_data = torch.tensor(interictal_np, dtype=torch.float32)\n",
    "\n",
    "print(f\"Ictal data shape {ictal_data.shape}\")\n",
    "print(f\"Interictal data shape {interictal_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998f55b8-356f-46ed-81ce-66f59a64c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, ictal_data, interictal_data):\n",
    "        # Ensure the data is converted to tensors\n",
    "        self.data = torch.cat([ictal_data, interictal_data])\n",
    "        # Labels for ictal and interictal data\n",
    "        self.labels = torch.cat(\n",
    "            [\n",
    "                torch.ones(len(ictal_data)),  # Ictal = 1\n",
    "                torch.zeros(len(interictal_data)),  # Interictal = 0\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_raw = self.data[idx]  # EEG data of shape (22, 2048)\n",
    "        label = self.labels[idx].long()  # Label: 0 (interictal) or 1 (ictal)\n",
    "        return eeg_raw, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5893c26c-aad0-41ea-bd22-6c06d0dda8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(ictal_data, interictal_data)\n",
    "train_dataset, test_dataset, val_dataset = random_split(dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6eeebd-5204-4033-abdc-12a6860b40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from snntorch import SConv2dLSTM, surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01979a1-7c75-40bd-b5ca-7d2efeca464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STFTSpikeClassifier(nn.Module):\n",
    "    def __init__(self, input_channels=22):\n",
    "        super().__init__()\n",
    "\n",
    "        self.thr = 0.05\n",
    "        slope = 13.42287274232855\n",
    "        beta = 0.9181805491303656\n",
    "        p1 = 0.5083664100388336\n",
    "        p2 = 0.26260898840708335\n",
    "        spike_grad = surrogate.straight_through_estimator()\n",
    "        spike_grad2 = surrogate.fast_sigmoid(slope=slope)\n",
    "\n",
    "        # initialize layers - note input_channels=22 for your STFT data\n",
    "        self.lstm1 = SConv2dLSTM(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            max_pool=(2, 1),\n",
    "            threshold=self.thr,\n",
    "            spike_grad=spike_grad,\n",
    "        )\n",
    "        self.lstm2 = SConv2dLSTM(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            max_pool=(2, 1),\n",
    "            threshold=self.thr,\n",
    "            spike_grad=spike_grad,\n",
    "        )\n",
    "        self.lstm3 = snn.SConv2dLSTM(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            max_pool=(2, 1),\n",
    "            threshold=self.thr,\n",
    "            spike_grad=spike_grad,\n",
    "        )\n",
    "\n",
    "        # Calculate the flattened size based on your frequency dimension (129)\n",
    "        # After 3 max-pooling layers (each dividing by 2), size becomes: 129 → 64 → 32 → 16\n",
    "        # For time dimension: 1 (we process one time step at a time)\n",
    "        self.fc1 = nn.Linear(\n",
    "            64 * 16 * 1, 512\n",
    "        )  # Adjust this based on actual output size\n",
    "\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad2, threshold=self.thr)\n",
    "        self.dropout1 = nn.Dropout(p1)\n",
    "        self.fc2 = nn.Linear(512, 2)  # Assuming binary classification\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad2, threshold=self.thr)\n",
    "        self.dropout2 = nn.Dropout(p2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels=22, freq=129, time=57)\n",
    "        time_steps = x.size(3)\n",
    "\n",
    "        # Initialize LIF state variables\n",
    "        mem4 = self.lif1.init_leaky()\n",
    "        mem5 = self.lif2.init_leaky()\n",
    "        syn1, mem1 = self.lstm1.init_sconv2dlstm()\n",
    "        syn2, mem2 = self.lstm2.init_sconv2dlstm()\n",
    "        syn3, mem3 = self.lstm3.init_sconv2dlstm()\n",
    "\n",
    "        # Output recording\n",
    "        spk5_rec = []\n",
    "        mem5_rec = []\n",
    "\n",
    "        # Process each time step\n",
    "        for step in range(time_steps):\n",
    "            # Extract the current time step and prepare input\n",
    "            # x_t shape: (batch, channels=22, freq=129, time=1)\n",
    "            x_t = x[:, :, :, step].unsqueeze(-1)\n",
    "\n",
    "            # Pass through SConv2dLSTM layers\n",
    "            spk1, syn1, mem1 = self.lstm1(x_t, syn1, mem1)\n",
    "            spk2, syn2, mem2 = self.lstm2(spk1, syn2, mem2)\n",
    "            spk3, syn3, mem3 = self.lstm3(spk2, syn3, mem3)\n",
    "\n",
    "            # Flatten and feed through fully connected layers\n",
    "            cur4 = self.dropout1(self.fc1(spk3.flatten(1)))\n",
    "            spk4, mem4 = self.lif1(cur4, mem4)\n",
    "\n",
    "            cur5 = self.dropout2(self.fc2(spk4))\n",
    "            spk5, mem5 = self.lif2(cur5, mem5)\n",
    "\n",
    "            # Record output spikes and membrane potentials\n",
    "            spk5_rec.append(spk5)\n",
    "            mem5_rec.append(mem5)\n",
    "\n",
    "        # Stack time steps\n",
    "        return torch.stack(spk5_rec), torch.stack(mem5_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90989cbe-1f93-40e3-aff2-d3e00c265e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = STFTSpikeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f55942-9916-43cf-adc4-23d9ef85835f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_spiking_eeg_model_2.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/serialization.py:1462\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/serialization.py:1964\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   1962\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   1963\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1965\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1967\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/_weights_only_unpickler.py:512\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    504\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    505\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    506\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    507\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    508\u001b[39m     ):\n\u001b[32m    509\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    510\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    511\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    514\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/serialization.py:1928\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/serialization.py:1900\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   1895\u001b[39m         storage.byteswap(dtype)\n\u001b[32m   1897\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   1898\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   1899\u001b[39m typed_storage = torch.storage.TypedStorage(\n\u001b[32m-> \u001b[39m\u001b[32m1900\u001b[39m     wrap_storage=\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1901\u001b[39m     dtype=dtype,\n\u001b[32m   1902\u001b[39m     _internal=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1903\u001b[39m )\n\u001b[32m   1905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typed_storage._data_ptr() != \u001b[32m0\u001b[39m:\n\u001b[32m   1906\u001b[39m     loaded_storages[key] = typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/serialization.py:693\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    674\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    675\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    690\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    691\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/serialization.py:632\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m    631\u001b[39m     device = _validate_device(location, backend_name)\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/storage.py:292\u001b[39m, in \u001b[36m_StorageBase.to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch.device):\n\u001b[32m    291\u001b[39m     device = torch.device(device)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/_utils.py:99\u001b[39m, in \u001b[36m_to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m     97\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_sparse\n\u001b[32m     98\u001b[39m     ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice.type.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     untyped_storage = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     untyped_storage.copy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_spiking_eeg_model_2.pth', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0ddca-05bd-452f-9c09-1a5b957a4b00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

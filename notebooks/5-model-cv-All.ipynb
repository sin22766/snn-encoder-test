{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d85389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload all\n",
    "\n",
    "%aimport -torch\n",
    "%aimport -matplotlib\n",
    "%aimport -seaborn\n",
    "%aimport -numpy\n",
    "%aimport -pandas\n",
    "%aimport -scipy\n",
    "%aimport -lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58ebcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-11 21:14:25.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36meeg_snn_encoder.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /workspace/snn-encoder-test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from eeg_snn_encoder.config import PROCESSED_DATA_DIR\n",
    "from eeg_snn_encoder.dataset import CHBMITDataset\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "torch.manual_seed(47)\n",
    "random.seed(47)\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6c4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = CHBMITDataset(PROCESSED_DATA_DIR / \"stft_normalized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292cc055",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tuning_encoder = \"be\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3e7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fine_study = optuna.load_study(\n",
    "    study_name=f\"model-fine-tuning-{tuning_encoder}-new\",\n",
    "    storage=os.environ[\"OPTUNA_CONN_STRING\"],\n",
    ")\n",
    "\n",
    "best_params = fine_study.best_params\n",
    "best_trial = fine_study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187a097-448e-4ea7-899e-cf4bb854281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_snn_encoder.models.classifier import ModelConfig\n",
    "from eeg_snn_encoder.models.lightning import OptimizerConfig\n",
    "from eeg_snn_encoder.tuning import ENCODER_TUNING_FUNCTIONS\n",
    "\n",
    "model_params: ModelConfig = {\n",
    "    \"threshold\": best_params[\"threshold\"],\n",
    "    \"slope\": best_params[\"slope\"],\n",
    "    \"beta\": best_params[\"beta\"],\n",
    "    \"dropout_rate1\": best_params[\"dropout_rate1\"],\n",
    "    \"dropout_rate2\": best_params[\"dropout_rate2\"],\n",
    "}\n",
    "\n",
    "optimizer_params: OptimizerConfig = {\n",
    "    \"lr\": best_params[\"lr\"],\n",
    "    \"weight_decay\": best_params[\"weight_decay\"],\n",
    "    \"scheduler_factor\": best_params[\"scheduler_factor\"],\n",
    "    \"scheduler_patience\": best_params[\"scheduler_patience\"],\n",
    "}\n",
    "\n",
    "encoder = ENCODER_TUNING_FUNCTIONS[tuning_encoder](best_trial) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146d3d2-86d1-4b2f-b479-a5a0141e4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from loguru import logger\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "from eeg_snn_encoder.config import MODELS_DIR\n",
    "from eeg_snn_encoder.models.lightning import LitSeizureClassifier\n",
    "\n",
    "logger.info(f\"Starting {tuning_encoder}-encoder final evaluation\")\n",
    "logger.info(f\"Params model:{model_params}, optimizer:{optimizer_params}, encoder:{encoder}\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "generator = torch.manual_seed(42)\n",
    "\n",
    "for fold, (train_val_ids, test_ids) in enumerate(kfold.split(dataset)): # type: ignore\n",
    "    logger.info(f\"Starting fold {fold + 1} of {kfold.get_n_splits()} {tuning_encoder}-encoder\")\n",
    "\n",
    "    train_ids, val_ids = train_test_split(\n",
    "        train_val_ids, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_ids)\n",
    "    val_sampler = SubsetRandomSampler(val_ids)\n",
    "    test_sampler = SubsetRandomSampler(test_ids) # type: ignore\n",
    "\n",
    "    trainloader = DataLoader(dataset, batch_size=512, sampler=train_sampler, generator=generator)\n",
    "    valloader = DataLoader(dataset, batch_size=512, sampler=val_sampler, generator=generator)\n",
    "    testloader = DataLoader(dataset, batch_size=512, sampler=test_sampler, generator=generator)\n",
    "\n",
    "    lit_model = LitSeizureClassifier(\n",
    "            model_config=model_params,\n",
    "            optimizer_config=optimizer_params,\n",
    "            spike_encoder=encoder,\n",
    "        )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "            max_epochs=50,\n",
    "            accelerator=\"auto\",\n",
    "            devices=\"auto\",\n",
    "            strategy=\"auto\",\n",
    "            default_root_dir=MODELS_DIR / f\"{tuning_encoder}_encoder\",\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)],\n",
    "            logger=False,\n",
    "        )\n",
    "\n",
    "    trainer.fit(lit_model, trainloader, valloader)\n",
    "    trainer.test(lit_model, testloader, ckpt_path=\"best\")\n",
    "\n",
    "    test_loss = trainer.callback_metrics[\"test_loss\"].item()\n",
    "    test_acc = trainer.callback_metrics[\"test_acc\"].item()\n",
    "    test_precision = trainer.callback_metrics[\"test_precision\"].item()\n",
    "    test_recall = trainer.callback_metrics[\"test_recall\"].item()\n",
    "    test_f1 = trainer.callback_metrics[\"test_f1\"].item()\n",
    "    test_mse = trainer.callback_metrics[\"test_mse\"].item()\n",
    "    test_total_spikes = trainer.callback_metrics[\"test_total_spikes\"].item()\n",
    "\n",
    "    logger.info(\n",
    "        f\"{tuning_encoder}-encoder \",\n",
    "        f\"Fold {fold + 1} - Test Loss: {test_loss:.4f}, \"\n",
    "        f\"Test Accuracy: {test_acc:.4f}, \"\n",
    "        f\"Test Precision: {test_precision:.4f}, \"\n",
    "        f\"Test Recall: {test_recall:.4f}, \"\n",
    "        f\"Test F1: {test_f1:.4f}, \"\n",
    "        f\"Test MSE: {test_mse:.4f}, \"\n",
    "        f\"Test Total Spikes: {test_total_spikes:.4f}\",\n",
    "    )\n",
    "\n",
    "    fold_results.append(\n",
    "        {\n",
    "            \"fold\": fold,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_mse\": test_mse,\n",
    "            \"test_total_spikes\": test_total_spikes,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    del lit_model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ac793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from eeg_snn_encoder.config import REPORTS_DIR\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "results_df.set_index(\"fold\", inplace=True)\n",
    "\n",
    "results_df.to_csv(REPORTS_DIR / f\"{tuning_encoder}_model_results_new.csv\", index=True)\n",
    "\n",
    "params_file = REPORTS_DIR / f\"{tuning_encoder}_model_params_new.json\"\n",
    "\n",
    "params_file.write_text(\n",
    "    json.dumps(\n",
    "        {\n",
    "            \"model_params\": model_params,\n",
    "            \"optimizer_params\": optimizer_params,\n",
    "            \"encoder_params\": encoder,\n",
    "        },\n",
    "        indent=4,\n",
    "    )\n",
    ")\n",
    "logger.info(f\"Results and parameters saved to {REPORTS_DIR} for {tuning_encoder}-encoder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
